iuyiuyi
q()
321+321
2137182378*13123
q()
q()
gotwd()
getwd()
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan.pop)
View(japan_pop_edited)
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan_pop_edited)
setwd(qa_class5_files)
getwd()
setwd(qa_class5_files)
setwd("qa_class5_files")
getwd
getwd()
setwd("qa_class5_files")
setwd("Quantitative Analysis R")
getwd()
ls()
setwd("clear(")
clear()
q()
setwd("/Users/TIZONA/Desktop/Political Text Analysis R/Week10_files")
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
# As ever, we'll use Tidyverse, readtext, and Quanteda:
library(tidyverse)
library(readtext)
library(quanteda)
# We're also using a new library this week, `stm`
if(!require("stm")) {install.packages("stm"); library(stm)}
news <- readtext("guardian_21.csv", text_field = "Text")
news
View(news)
news$Month <- month(news$Date)
news$Day <- day(news$Date)
news$text <- gsub("’", "'", news$text)
news_dfm <- news %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
split_hyphens = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2)
news_dfm
news_dfm_trim <- dfm_trim(news_dfm, min_docfreq = 20)
news_dfm_trim
news_dfm_trim[ ntoken(news_dfm_trim) == 0, ]
# Here we see that 33 documents are now entirely blank. We have to remove those.
news_dfm_trim <- news_dfm_trim[ ntoken(news_dfm_trim) > 0, ]
news_dfm_trim
head(docvars(news_dfm_trim))
news_stm_dfm <- convert(news_dfm_trim,
to = "stm",
docvars( news_dfm_trim, c("Section", "Month", "Headline") )
)
set.seed(123)
news_stm_basic <- stm(news_stm_dfm$documents,
news_stm_dfm$vocab,
K = 15,
max.em.its = 100)
labelTopics( news_stm_basic, n = 8)
set.seed(123)
news_stm_basic <- stm(news_stm_dfm$documents,
news_stm_dfm$vocab,
K = 15,
max.em.its = 100)
labelTopics( news_stm_basic, n = 8)
plot.STM(news_stm_basic, type = "summary", labeltype = c("frex"), n=5)
plot.STM(news_stm_basic, type = "hist", labeltype = c("frex"))
# 2.2   Naming Topics
newsBasic_names <- c("Heealthcare",
"Gender",
"Calture",
"Afganistan",
"Natrue Disaster",
"UK Opposition",
"Covid-19",
"SNS",
"Nature",
"Crime",
"Us Politics",
"Energy",
"UK Gov",
"Cost of living",
"Supply Chains")
plot.STM(news_stm_basic, type = "summary",
topic.names = newsBasic_names, custom.labels = "")
news_stm_basic_corr <- topicCorr(news_stm_basic)
plot.topicCorr(news_stm_basic_corr, vlabels = newsBasic_names)
set.seed(456)
news_stm <- stm(news_stm_dfm$documents,
news_stm_dfm$vocab,
K = 15,
prevalence =~ Section + s(Month),
data = news_stm_dfm$meta,
max.em.its = 100)
labelTopics( news_stm, n = 6)
plot.STM(news_stm_basic, type = "summary", labeltype = c("frex"), n=5)
newsStruc_names <- c("Health Care",
"Medical Research",
"Calture",
"Afganistan",
"Natural Disaster",
"UK Opposition",
"Covid-19",
"SNS",
"Nature",
"Policing",
"US Politics",
"Energy",
"UK Gov",
"Cost of living",
"Supply Chain")
news_stm_corr <- topicCorr(news_stm)
plot.topicCorr(news_stm_corr, vlabels = newsStruc_names)
findThoughts(news_stm, texts = news_stm_dfm$meta$Headline, n = 3, topics = 1:15)
monthEffects <- estimateEffect( 1:15 ~ s(Month),
news_stm,
meta = news_stm_dfm$meta,
uncertainty = "Global" )
plot(monthEffects, "Month",
method = "continuous", topics = 4,
model = news_stm,
printlegend = FALSE)
plot(monthEffects, "Month",
method = "continuous", topics = 7,
model = news_stm,
printlegend = FALSE)
sectionEffects <- estimateEffect( 1:15 ~ Section,
news_stm,
meta = news_stm_dfm$meta,
uncertainty = "Global" )
unique(news_stm_dfm$meta$Section)
plot(sectionEffects, covariate = "Section", topics = 1:15,
model = news_stm, method = "difference",
cov.value1 = "News", cov.value2 = "Business",
xlab = "More Business ... More News",
main = "Effect of News vs. Business sections",
xlim = c(-.2, .2), labeltype = "custom",
custom.labels = newsStruc_names)
setwd("~/Desktop/Political Text Analysis/Week10_files")
setwd("~/Desktop/Political Text Analysis/Week9_files")
setwd("/Users/TIZONA/Desktop/Political Text Analysis/Class9_files")
library(tidyverse)
library(readtext)
library(quanteda)
library(quanteda.textmodels)
# We also have a new library to use today for topic modelling.
# These commands will check if it's installed already, and install it for
# you if not:
if(!require("topicmodels")) {install.packages("topicmodels"); library(topicmodels)}
if(!require("wordcloud")) {install.packages("wordcloud"); library(wordcloud)}
sotu <- readtext("./SOTU/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Year", "President", "Party"))
sotu
View(sotu)
View(sotu)
View(sotu)
news <- readtext("guardian_21.csv", text_field = "Text")
setwd("/Users/TIZONA/Desktop/Political Text Analysis/Week10_files")
news <- readtext("guardian_21.csv", text_field = "Text")
View(news)
setwd("/Users/TIZONA/Desktop")
library(tidyverse)
library(readtext)
library(quanteda)
library(wordcloud)
library(topicmodels)
library(stm)
speech <- readtext("./speechfile2/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "SS", "Num"))
setwd("/Users/TIZONA/Desktop/Political Text Analysis/2023ss_analysis")
speech <- readtext("./speechfile2/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("./speechfile2/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("/Users/TIZONA/Desktop/PTA/2023ss_analysis/speechfile2*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("/Users/TIZONA/Desktop/PTA/2023ss_analysis/speechfile2/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
library(tidyverse)
library(readtext)
library(quanteda)
library(quanteda.textmodels)
library(stm)
library(topicmodels)
library(wordcloud)
speech <- readtext("/Users/TIZONA/Desktop/PTA/2023ss_analysis/speechfile2/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("/Users/TIZONA/Desktop/PTA/2023ss_analysis/SF/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("/Users/TIZONA/Desktop/PTA/2023ss_analysis/SF*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("./SF/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party"))
speech <- readtext("./SF/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "President", "Party", "Num"))
View(speech)
speech$Month <- month(speech$Date)
speech$Day <- day(speech$Date)
speech$text <- gsub("’", "'", speech$text)
speech_dfm <- speech %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2)
View(speech_dfm)
news_dfm_trim <- dfm_trim(news_dfm, min_docfreq = 20)
speech_dfm_trim <- dfm_trim(speech_dfm, min_docfreq = 20)
news_dfm_trim[ ntoken(news_dfm_trim) == 0, ]
speech_dfm_trim[ ntoken(speech_dfm_trim) == 0, ]
speech_dfm_trim
head(docvars(news_dfm_trim))
head(docvars(speech_dfm_trim))
speech_stm_dfm <- convert(speech_dfm_trim,
to = "stm",
docvars( speech_dfm_trim, c("Num", "Month", "Day") )
)
set.seed(123)
speech_stm_basic <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 15,
max.em.its = 100)
labelTopics( speech_stm_basic, n = 8)
plot.STM(speech_stm_basic, type = "summary", labeltype = c("frex"), n=5)
plot.STM(news_stm_basic, type = "hist", labeltype = c("frex"))
plot.STM(speech_stm_basic, type = "hist", labeltype = c("frex"))
speech_stm_basic_corr <- topicCorr(speech_stm_basic)
plot.topicCorr(speech_stm_basic_corr, vlabels = topic.names)
speech_stm_basic_corr <- topicCorr(speech_stm_basic)
plot.topicCorr(speech_stm_basic_corr, vlabels = names)
newsBasic_names <- c("1",
"2",
"3",
"4",
"5",
"6",
"7",
"8",
"9",
"10",
"11",
"12",
"13",
"14",
"15")
plot.STM(news_stm_basic, type = "summary",
topic.names = newsBasic_names, custom.labels = "")
plot.STM(speech_stm_basic, type = "summary",
topic.names = newsBasic_names, custom.labels = "")
speech_stm_basic_corr <- topicCorr(speech_stm_basic)
plot.topicCorr(speech_stm_basic_corr, vlabels = newsBasic_names)
set.seed(456)
news_stm <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 15,
prevalence =~ Section + s(Month),
data = speech_stm_dfm$meta,
max.em.its = 100)
View(speech_dfm)
set.seed(456)
news_stm <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 15,
prevalence =~ s(Month),
data = speech_stm_dfm$meta,
max.em.its = 100)
monthEffects <- estimateEffect( 1:15 ~ s(Month),
speech_stm,
meta = speech_stm_dfm$meta,
uncertainty = "Global" )
speech_stm <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 15,
prevalence =~ s(Month),
data = speech_stm_dfm$meta,
max.em.its = 100)
rm news_stm
rm "news_stm"
rm news_stm
monthEffects <- estimateEffect( 1:15 ~ s(Month),
speech_stm,
meta = speech_stm_dfm$meta,
uncertainty = "Global" )
plot(monthEffects, "Month",
method = "continuous", topics = 4,
model = speech_stm,
printlegend = FALSE)
plot(monthEffects, "Month",
method = "continuous", topics = 7,
model = speech_stm,
printlegend = FALSE)
set.seed(123)
speech_stm_basic <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 10)
labelTopics( speech_stm_basic, n = 8)
plot.STM(speech_stm_basic, type = "summary", labeltype = c("frex"), n=5)
plot.STM(speech_stm_basic, type = "hist", labeltype = c("frex"))
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(speech_stm_basic$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
plot.STM(speech_stm_basic, type = "summary", labeltype = c("frex"), n=5)
labelTopics( speech_stm_basic, n = 10)
