iuyiuyi
q()
321+321
2137182378*13123
q()
q()
gotwd()
getwd()
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan.pop)
View(japan_pop_edited)
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan_pop_edited)
setwd(qa_class5_files)
getwd()
setwd(qa_class5_files)
setwd("qa_class5_files")
getwd
getwd()
setwd("qa_class5_files")
setwd("Quantitative Analysis R")
getwd()
ls()
setwd("clear(")
clear()
q()
setwd("/Users/TIZONA/Desktop/Political Text Analysis R/Class9_files")
library(tidyverse)
library(readtext)
library(quanteda)
library(quanteda.textmodels)
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
if(!require("topicmodels")) {install.packages("topicmodels"); library(topicmodels)}
if(!require("wordcloud")) {install.packages("wordcloud"); library(wordcloud)}
sotu <- readtext("./SOTU/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Year", "President", "Party"))
sotu
sotu$text <- gsub("'", " ", sotu$text)
sotu$text <- gsub("â€™", " ", sotu$text)
# (Why are we doing it twice? Because there are two subtly different symbols
#  for apostrophe, and we can't be sure which one is used in the text...)
sotu_dfm <- sotu %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2)
View(sotu_dfm)
View(sotu_dfm)
populism_dict <- dictionary(list(populism = c("elit*", "consensus*", "undemocratic*",
"referend*", "corrupt*", "propagand",
"politici*", "*deceit*", "*deceiv*",
"*betray*", "shame*", "scandal*",
"truth*", "dishonest*", "establishm*",
"ruling*", "state", "fake"),
liberalism = c("liber*", "free*", "indiv*",
"open*", "law*", "rules",
"order", "rights", "trade",
"global", "inter*", "trans*",
"minori*", "exchange", "market*")))
populism_dict
sotu_populism <- dfm_lookup(sotu_dfm, populism_dict)
sotu_populism
sotu_populism_prop <- dfm_weight(sotu_populism, scheme = "prop")
sotu_populism_prop
View(sotu_populism_prop)
View(populism_dict)
sotu_pop_df <- convert(sotu_populism_prop, "data.frame")
ggplot(data = sotu_pop_df, aes(x = doc_id, y = populism)) +
geom_col() +
ylim(0.0, 1.0) +
theme_linedraw() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Share of populism [%]")
sotu_byPres_df <- sotu_dfm %>%
dfm_group(groups = President) %>%
dfm_lookup(populism_dict) %>%
dfm_weight(scheme = "prop") %>%
convert("data.frame")
ggplot(data = sotu_byPres_df, aes(x = doc_id, y = populism)) +
geom_col() +
ylim(0.0, 1.0) +
theme_linedraw() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Share of populism [%]")
lexiTopic <- dictionary(file = "./dictionaries/policy_agendas_english.lcd")
lexiTopic
sotu_tokens <- sotu %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en")
sotu_lexiTopic <- sotu_tokens %>%
tokens_lookup(lexiTopic)
sotu_lexiTopic
sotu_lexiTopic <- sotu_lexiTopic %>%
dfm() %>%
dfm_weight(scheme = "prop") %>%
convert("data.frame")
sotu_lexiTopic
sotu_lexiTopic <- sotu_lexiTopic %>%
select(where(~ max(.x) > 0.12))
sotu_lexiTopic %>%
pivot_longer(macroeconomics:defence, names_to = "Topic", values_to = "Proportion") %>%
ggplot(aes(doc_id, Proportion, group = Topic, fill = Topic)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Topic Proportion [%]")
sotu_lexiTopic <- sotu_lexiTopic %>%
dfm() %>%
dfm_weight(scheme = "prop") %>%
convert("data.frame")
sotu_tokens <- sotu %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en")
sotu_lexiTopic <- sotu_tokens %>%
tokens_lookup(lexiTopic)
sotu_lexiTopic
sotu_lexiTopic <- sotu_lexiTopic %>%
dfm() %>%
dfm_weight(scheme = "prop") %>%
convert("data.frame")
sotu_lexiTopic
sotu_lexiTopic <- sotu_lexiTopic %>%
select(where(~ max(.x) > 0.12))
View(sotu_lexiTopic)
sotu_lexiTopic
sotu_lexiTopic %>%
pivot_longer(macroeconomics:defence, names_to = "Topic", values_to = "Proportion") %>%
ggplot(aes(doc_id, Proportion, group = Topic, fill = Topic)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Topic Proportion [%]")
head(data_dictionary_LSD2015)
sotu_sentiment <- sotu_dfm %>%
dfm_lookup(dictionary = data_dictionary_LSD2015[1:2]) %>%
dfm_weight(scheme = "prop") %>%
convert("data.frame")
sotu_sentiment
sotu_sentiment %>%
pivot_longer(negative:positive, names_to = "Sentiment", values_to = "Proportion") %>%
ggplot(aes(doc_id, Proportion, group = Sentiment, fill = Sentiment)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Sentiment Proportion [%]")
sotu_dfm_trim <- dfm_trim(sotu_dfm,
min_termfreq = 5, min_docfreq = 3,
max_docfreq = 9)
sotu_dfm_trim
sotu_tm <- convert(sotu_dfm_trim, "topicmodels")
set.seed(100)
sotu_lda.10 <- LDA(sotu_tm, method = "Gibbs", k = 10)
sotu_lda.10
as.data.frame(terms(sotu_lda.10, 10))
set.seed(100)
sotu_lda.10 <- LDA(sotu_tm, method = "Gibbs", k = 10)
sotu_lda.10
as.data.frame(terms(sotu_lda.10, 10))
sotu_lda.10
as.data.frame(terms(sotu_lda.10, 10))
set.seed(100)
sotu_lda.8 <- LDA(sotu_tm, method = "Gibbs", k = 8)
set.seed(100)
sotu_lda.12 <- LDA(sotu_tm, method = "Gibbs", k = 12)
as.data.frame(terms(sotu_lda.8, 10))
as.data.frame(terms(sotu_lda.12, 10))
tm_result <- posterior(sotu_lda.8)
tm_result$topics
top5terms <- terms(sotu_lda.8, 5)
topicNames <- apply(top5terms, 2, paste, collapse=" ")
topicNames
theta <- data.frame(tm_result$topics)
colnames(theta) <- topicNames
theta %>%
mutate(Doc_ID = row.names(.)) %>%
pivot_longer(topicNames[1]:topicNames[8], names_to = "Topic", values_to = "Proportion") %>%
ggplot(aes(Doc_ID, Proportion, group = Topic, fill = Topic)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Topic Proportion [%]")
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
tm_result <- posterior(sotu_lda.8)
tm_result$topics
View(tm_result)
View(theta)
theta %>%
mutate(Doc_ID = row.names(.)) %>%
pivot_longer(topicNames[1]:topicNames[8], names_to = "Topic", values_to = "Proportion") %>%
ggplot(aes(Doc_ID, Proportion, group = Topic, fill = Topic)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Topic Proportion [%]")
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
View(tm_result)
tm_result$terms
top5terms <- terms(sotu_lda.8, 5)
topicNames <- apply(top5terms, 2, paste, collapse=" ")
topicNames
theta <- data.frame(tm_result$topics)
colnames(theta) <- topicNames
theta %>%
mutate(Doc_ID = row.names(.)) %>%
pivot_longer(topicNames[1]:topicNames[8], names_to = "Topic", values_to = "Proportion") %>%
ggplot(aes(Doc_ID, Proportion, group = Topic, fill = Topic)) +
geom_bar(stat = 'identity') +
scale_colour_brewer(palette = "Set1") + scale_fill_brewer(palette = "Pastel1") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
xlab("") +
ylab("Topic Proportion [%]")
target_topic <- 1   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
target_topic <- 8   # Let's look at topic number eight.
topterms <- sort(tm_result$terms[target_topic,], decreasing=TRUE)[1:20]
words <- names(topterms)
wordcloud(words, topterms, random.order = FALSE, color = brewer.pal(8, "Dark2"))
