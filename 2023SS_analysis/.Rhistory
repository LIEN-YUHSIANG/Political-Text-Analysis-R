iuyiuyi
q()
321+321
2137182378*13123
q()
q()
gotwd()
getwd()
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan.pop)
View(japan_pop_edited)
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
load("~/Desktop/Quantitative Analysis R/qa_class5_files/japan_pop_edited.RData")
View(japan_pop_edited)
setwd(qa_class5_files)
getwd()
setwd(qa_class5_files)
setwd("qa_class5_files")
getwd
getwd()
setwd("qa_class5_files")
setwd("Quantitative Analysis R")
getwd()
ls()
setwd("clear(")
clear()
q()
setwd("/Users/TIZONA/Desktop/Political-Text-Analysis-R/2023SS_analysis")
library(tidyverse)
library(readtext)
library(quanteda)
library(quanteda.textmodels)
library(stm)
library(topicmodels)
library(wordcloud)
speech <- readtext("./SF/*.txt",
docvarsfrom = "filenames",
dvsep = "_",
docvarnames = c("Date", "Value", "Type", "Num"))
View(speech)
speech$Month <- month(speech$Date)
speech$Day <- day(speech$Date)
speech$text <- gsub("â€™", "'", speech$text)
speech_dfm <- speech %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_separators = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2)
speech_dfm_trim <- dfm_trim(speech_dfm, min_docfreq = 20)
speech_dfm_trim[ ntoken(speech_dfm_trim) == 0, ]
speech_dfm_trim
head(docvars(speech_dfm_trim))
speech_stm_dfm <- convert(speech_dfm_trim,
to = "stm",
docvars( speech_dfm_trim, c("Month", "Day") )
)
View(speech_stm_dfm)
head(docvars(speech_dfm_trim))
speech_stm_dfm <- convert(speech_dfm_trim,
to = "stm",
docvars( speech_dfm_trim, c("Num", "Month", "Day") )
)
set.seed(123)
speech_stm_basic <- stm(speech_stm_dfm$documents,
speech_stm_dfm$vocab,
K = 10)
labelTopics( speech_stm_basic, n = 10)
plot.STM(speech_stm_basic, type = "summary", labeltype = c("frex"), n=5)
