setwd("/Users/TIZONA/Desktop/Political Text Analysis R/Week12_files")
Sys.setlocale("LC_ALL", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_GB.UTF-8")
setwd("~/Dropbox/Waseda/Political Text Analysis 2023/Week12")
if(!require("caret")) {install.packages("caret"); library(caret)}
if(!require("naivebayes")) {install.packages("naivebayes"); library(naivebayes)}
if(!require("e1071")) {install.packages("e1071"); library(e1071)}
if(!require("randomForest")) {install.packages("randomForest"); library(randomForest)}
library(tidyverse)
library(readtext)
library(quanteda)
if(!require("caret")) {install.packages("caret"); library(caret)}
if(!require("naivebayes")) {install.packages("naivebayes"); library(naivebayes)}
if(!require("e1071")) {install.packages("e1071"); library(e1071)}
if(!require("randomForest")) {install.packages("randomForest"); library(randomForest)}
library(caret)
library(tidyverse)
library(readtext)
library(quanteda)
library(tidyverse)
library(readtext)
library(quanteda)
# We have quite a lot of new software to install this week...
if(!require("caret")) {install.packages("caret"); library(caret)}
if(!require("naivebayes")) {install.packages("naivebayes"); library(naivebayes)}
if(!require("e1071")) {install.packages("e1071"); library(e1071)}
if(!require("randomForest")) {install.packages("randomForest"); library(randomForest)}
biden_tweets <- readtext("biden_tweets.csv", text_field = "text")
trump_tweets <- readtext("trump_tweets.csv", text_field = "text")
head(biden_tweets)
table(biden_tweets$label)
biden_dfm <- biden_tweets %>%
mutate(text = gsub("’", "'", .$text)) %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
split_hyphens = TRUE,
remove_separators = TRUE,
remove_url = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_remove(c("0*", "@*")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2) %>%
dfm_trim(min_docfreq = 5)
biden_dfm$label <- as.factor(biden_dfm@docvars$label)
View(biden_dfm)
View(biden_tweets)
table(biden_tweets$label)
biden_dfm[ ntoken(biden_dfm) == 0, ]
biden_dfm$label <- as.factor(biden_dfm@docvars$label)
setwd("/Users/TIZONA/Desktop/Political Text Analysis/Week12_files")
library(tidyverse)
library(readtext)
library(quanteda)
library(tidyverse)
setwd("~/Desktop/Political Text Analysis/Week12_files")
library(tidyverse)
library(readtext)
library(quanteda)
if(!require("caret")) {install.packages("caret"); library(caret)}
if(!require("naivebayes")) {install.packages("naivebayes"); library(naivebayes)}
if(!require("e1071")) {install.packages("e1071"); library(e1071)}
if(!require("randomForest")) {install.packages("randomForest"); library(randomForest)}
biden_tweets <- readtext("biden_tweets.csv", text_field = "text")
trump_tweets <- readtext("trump_tweets.csv", text_field = "text")
# Let's focus on Biden for now.
head(biden_tweets)
# We can check to see what the proportion of different labels in the corpus is.
table(biden_tweets$label)
biden_dfm <- biden_tweets %>%
mutate(text = gsub("’", "'", .$text)) %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
split_hyphens = TRUE,
remove_separators = TRUE,
remove_url = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_remove(c("0*", "@*")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2) %>%
dfm_trim(min_docfreq = 5)
biden_dfm[ ntoken(biden_dfm) == 0, ]
biden_dfm$label <- as.factor(biden_dfm@docvars$label)
biden_dfm$numeric_id <- 1:nrow(biden_dfm)
View(biden_dfm)
set.seed(1234)
trainIndex <- createDataPartition(biden_dfm$label,
p = .8,
list = TRUE,
times = 1)
head(trainIndex)
biden_dfm.train <- dfm_subset(biden_dfm, biden_dfm$numeric_id %in% trainIndex$Resample1 )
biden_dfm.test <- dfm_subset(biden_dfm, !biden_dfm$numeric_id %in% trainIndex$Resample1 )
biden_dfm.train
biden_dfm.test
str(biden_dfm.train$label)
set.seed(1234)
biden.nb <- multinomial_naive_bayes(x = biden.train,
y = biden_dfm.train$label)
biden.train <- as.matrix(biden_dfm.train)
biden.test <- as.matrix(biden_dfm.test)
str(biden_dfm.train$label)
set.seed(1234)
biden.nb <- multinomial_naive_bayes(x = biden.train,
y = biden_dfm.train$label)
summary(biden.nb)
biden_nb.predict <- predict(biden.nb, newdata = biden.test)
confusionMatrix(biden_nb.predict,
biden_dfm.test$label)
set.seed(1234)
biden.svm <- svm(x = biden.train,
y = biden_dfm.train$label)
# We can check its performance on the test set as seen below...
biden_svm.predict <- predict(biden.svm, biden.test)
confusionMatrix(biden_svm.predict,
biden_dfm.test$label)
set.seed(1234)
biden.rf <- randomForest(x = biden.train,
y = biden_dfm.train$label)
biden_rf.predict <- predict(biden.rf, biden.test)
confusionMatrix(biden_rf.predict,
biden_dfm.test$label)
trump_dfm <- trump_tweets %>%
mutate(text = gsub("’", "'", .$text)) %>%
corpus() %>%
tokens(remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
split_hyphens = TRUE,
remove_separators = TRUE,
remove_url = TRUE) %>%
tokens_remove(stopwords(language = "en")) %>%
tokens_remove(c("0*", "@*")) %>%
tokens_wordstem(language = "en") %>%
dfm() %>%
dfm_remove(min_nchar=2) %>%
dfm_trim(min_docfreq = 5)
trump_dfm[ ntoken(trump_dfm) == 0, ]
trump_dfm$label <- as.factor(trump_dfm@docvars$label)
biden_dfm[ ntoken(biden_dfm) == 0, ]
trump_dfm[ ntoken(trump_dfm) == 0, ]
trump_dfm <- trump_dfm[ ntoken(news_dfm) > 0, ]
trump_dfm[ ntoken(trump_dfm) == 0, ]
trump_dfm <- trump_dfm[ ntoken(trump_dfm) > 0, ]
trump_dfm[ ntoken(trump_dfm) == 0, ]
trump_dfm$label <- as.factor(trump_dfm@docvars$label)
trump_dfm$numeric_id <- 1:nrow(trump_dfm)
set.seed(1234)
trainIndex <- createDataPartition(trump_dfm$label,
p = .8,
list = TRUE,
times = 1)
head(trainIndex)
trump_dfm.train <- dfm_subset(trump_dfm, trump_dfm$numeric_id %in% trainIndex$Resample1 )
trump_dfm.test <- dfm_subset(trump_dfm, !trump_dfm$numeric_id %in% trainIndex$Resample1 )
trump_dfm.train
trump_dfm.test
trump.train <- as.matrix(trump_dfm.train)
trump.test <- as.matrix(trump_dfm.test)
str(biden_dfm.train$label)
set.seed(1234)
biden.nb <- multinomial_naive_bayes(x = biden.train,
y = biden_dfm.train$label)
summary(biden.nb)
biden_nb.predict <- predict(biden.nb, newdata = biden.test)
confusionMatrix(biden_nb.predict,
biden_dfm.test$label)
set.seed(1234)
biden.svm <- svm(x = biden.train,
y = biden_dfm.train$label)
biden_svm.predict <- predict(biden.svm, biden.test)
confusionMatrix(biden_svm.predict,
biden_dfm.test$label)
set.seed(1234)
biden.rf <- randomForest(x = biden.train,
y = biden_dfm.train$label)
biden_rf.predict <- predict(biden.rf, biden.test)
confusionMatrix(biden_rf.predict,
biden_dfm.test$label)
str(biden_dfm.train$label)
set.seed(1234)
trump.nb <- multinomial_naive_bayes(x = trump.train,
y = trump_dfm.train$label)
summary(trump.nb)
trump_nb.predict <- predict(trump.nb, newdata = trump.test)
confusionMatrix(trump_nb.predict,
trump_dfm.test$label)
set.seed(1234)
trump.svm <- svm(x = trump.train,
y = trump_dfm.train$label)
trump_svm.predict <- predict(trump.svm, trump.test)
confusionMatrix(trump_svm.predict,
trump_dfm.test$label)
set.seed(1234)
trump.rf <- randomForest(x = trump.train,
y = trump_dfm.train$label)
trump_rf.predict <- predict(trump.rf, trump.test)
confusionMatrix(trump_rf.predict,
trump_dfm.test$label)
